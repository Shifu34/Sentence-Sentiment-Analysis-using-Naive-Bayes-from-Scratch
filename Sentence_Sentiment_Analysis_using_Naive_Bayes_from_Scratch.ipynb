{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Welcome to the Notebook**\n",
        "\n",
        "---\n",
        "In this notebook you will go through simple steps to implement a naive bayes from scratch on a sentence sentiment Analysis.\n"
      ],
      "metadata": {
        "id": "MFIn7Rhj17yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "metadata": {
        "id": "UdDUZlHTHjWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading necessary packages\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "lem = WordNetLemmatizer() #intializing wird net lemmatizer"
      ],
      "metadata": {
        "id": "9zXK-lKVxJa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the vocabulary\n",
        "#Example vocabulary:  Toyota is the large car maker in world with Honda and Suzuki trail ranking has produce many best sell luxury model are rugged require more maintain not when it come to\n",
        "#Example Positive Vocabulary: Toyota is the largest car maker in the world with Honda and Suzuki trailing it in rankings Toyota has produced many best selling luxury car models Toyota cars are rugged\n",
        "#Example Negaitive Vocabulary: Toyota cars require more maintenance Toyota cars are not the best when it comes to luxury\n",
        "vocab= input(\"Enter your vocabulary: \")\n",
        "vocab_list=vocab.split()\n",
        "plus_class=input(\"Enter your positive vocabulary: \")\n",
        "plus_class_l=plus_class.split()\n",
        "neg_class=input(\"Enter your positive vocabulary: \")\n",
        "neg_class_l=neg_class.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9yzfoDqPL3A",
        "outputId": "23518201-76eb-41ae-f8ea-bb81d5ebdc7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your vocabulary: Toyota is the large car maker in world with Honda and Suzuki trail ranking has produce many best sell luxury model are rugged require more maintain not when it come to\n",
            "Enter your positive vocabulary: Toyota is the largest car maker in the world with Honda and Suzuki trailing it in rankings Toyota has produced many best selling luxury car models Toyota cars are rugged\n",
            "Enter your positive vocabulary: Toyota cars require more maintenance Toyota cars are not the best when it comes to luxury\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#applying lemmetization on the vocabulary\n",
        "final_vocab_list=[]\n",
        "for i in vocab_list:\n",
        "  i=lem.lemmatize(i, pos=\"v\")\n",
        "  final_vocab_list.append(i)\n",
        "#Applying Lemmetization on the positive vocabulary\n",
        "plus_class_list=[]\n",
        "for i in plus_class_l:\n",
        "  i=lem.lemmatize(i, pos=\"v\")\n",
        "  if(i==\"cars\"):\n",
        "    i=ps.stem(i)\n",
        "  plus_class_list.append(i)\n",
        "#Applying Lemmetization on the negative vocabulary\n",
        "neg_class_list=[]\n",
        "for i in neg_class_l:\n",
        "  i=lem.lemmatize(i, pos=\"v\")\n",
        "  if(i==\"cars\"):\n",
        "    i=ps.stem(i)\n",
        "  neg_class_list.append(i)"
      ],
      "metadata": {
        "id": "GM_xO2JtQADo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "In this Naive Bayes class, I have intizaling it in the constructor with vocabulary\n",
        "list and also with negative and positive class lists.\n",
        "After this there comes a function probability_calculator() which is basically getting\n",
        "test list and then calculating the negative and positive probablity and storing it.\n",
        "Then there come's a function predict(), which is predicting the positive/negative\n",
        "sentiment of the sentence. It also print negative for negative sentence and positive\n",
        "for positive probability.\n",
        "The display function is basically displaying positive and negative probabilities\n",
        "\"\"\"\n",
        "#Implementing Naive Bayes from scratch on the given problem\n",
        "class Naive_Bayes():\n",
        "  def __init__(self,vocab_list,plus_class_list,neg_class_list):\n",
        "    self.vocab=vocab_list\n",
        "    self.plus_class=plus_class_list\n",
        "    self.neg_class=neg_class_list\n",
        "    self.positive_prob=[]\n",
        "    self.negative_prob=[]\n",
        "\n",
        "  def probability_calculator(self,test_list):\n",
        "    for i in test_list:\n",
        "      no_occur_pos=0\n",
        "      for j in self.plus_class:\n",
        "        if i==j:\n",
        "          no_occur_pos=no_occur_pos+1\n",
        "      pos_p=(no_occur_pos+1)/(len(self.plus_class)+len(self.vocab))\n",
        "      self.positive_prob.append(pos_p)\n",
        "\n",
        "      no_occur_neg=0\n",
        "      for j in self.neg_class:\n",
        "        if i==j:\n",
        "          no_occur_neg=no_occur_neg+1\n",
        "      neg_p=(no_occur_neg+1)/(len(self.neg_class)+len(self.vocab))\n",
        "      self.negative_prob.append(neg_p)\n",
        "  def predict(self):\n",
        "    final_positive_prob=self.positive_prob[0]*self.positive_prob[1]*self.positive_prob[2]*self.positive_prob[3]*(3/5)\n",
        "    final_negative_prob=self.negative_prob[0]*self.negative_prob[1]*self.negative_prob[2]*self.negative_prob[3]*(2/5)\n",
        "    if final_positive_prob>final_negative_prob:\n",
        "      print(\"Negative\")\n",
        "    else:\n",
        "      print(\"Positive\")\n",
        "  def display(self):\n",
        "    print(\"postive_probabilities:\",self.positive_prob)\n",
        "    print(\"negative_probabilities:\",self.negative_prob)"
      ],
      "metadata": {
        "id": "3XDfW9zTUN7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is a test list\n",
        "test_list=[\"Toyota\",\"car\",\"best\",\"luxury\"]\n",
        "Naive_baye=Naive_Bayes(final_vocab_list,plus_class_list,neg_class_list) #initilizing naive bayes\n",
        "Naive_baye.probability_calculator(test_list) #calling probability calculator function\n",
        "Naive_baye.predict() #Predicting the sentiment of sentence\n",
        "Naive_baye.display() #Displaying the probabilities of words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8yq--BLcJtg",
        "outputId": "ace11cd7-04e7-4942-b2fa-6808f5430a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n",
            "postive_probabilities: [0.06557377049180328, 0.06557377049180328, 0.03278688524590164, 0.03278688524590164]\n",
            "negative_probabilities: [0.06382978723404255, 0.06382978723404255, 0.0425531914893617, 0.0425531914893617]\n"
          ]
        }
      ]
    }
  ]
}